{"cells":[{"cell_type":"markdown","source":["## Note- This is not rendered properly on github please take a look [here](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/1457916220563996/3123150065672593/1920439544921018/latest.html)\n\nLet me know at vijen1991@gmail.com if the link does not work (It might be 6 months or older) or there is any problem/doubts with the Notebook."],"metadata":{}},{"cell_type":"markdown","source":["### This Notebook serves as a tutorial for 2 purposes with Apache Spark\n1. It provides an analysis of the Movie Lens Dataset(It shows how the Aggregation methods are simple but very effective)\n2. Recommendation engine based on Collabrative filtering (ALS from MLlib)\n\nSome of the Links and references I have used are -\n1. Dataset can be found [here](https://grouplens.org/datasets/movielens/20m/) or at [kaggle](https://www.kaggle.com/grouplens/movielens-20m-dataset)\n2. edX Apache Spark course cs110 Assignment 2 (Movie Recommendation) I have used my own code from that notebook (Not providing my notebook link here just in case course is offered again with same Assignments) Side note -  It is one of the best and the most intense course series I have ever done.\n3. A More Scalable Way of Making Recommendations with MLlib - Xiangrui Meng [here](https://www.youtube.com/watch?v=Q0VXllYilM0&)\n4. I have used [Databricks community edition cloud](https://community.cloud.databricks.com). This is because we already have the required dataset mounted on the Cloud. Also, Databricks community edition has tons of features (I love the display feature) and the whole system is preconfigured.One important thing here (Also, a differentiating feature) is we do not need to create spark context or sql context object which is already created for us\n\nA caution Note- \nWe won't do collect() here as that will push all the data back to the Driver which might cause out of memory error."],"metadata":{}},{"cell_type":"code","source":["#We already have sc and sqlContext for us here\nprint sc\nprint sqlContext"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["### Getting the data\nIt is already mounted for us"],"metadata":{}},{"cell_type":"code","source":["import os\nfrom databricks_test_helper import Test\n\ndbfs_dir = '/databricks-datasets/cs110x/ml-20m/data-001'\n\n#We will use these 2 files for our analysis and collabrative filtering\nratings_filename = dbfs_dir + '/ratings.csv' \nmovies_filename = dbfs_dir + '/movies.csv'"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#This is a databricks feature\ndisplay(dbutils.fs.ls(dbfs_dir))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["dbutils.fs.head(movies_filename)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["### A Little analysis on the movies.csv\nWe will create 2 dataframes for our analysis which will make the visualization with Databricks display function pretty straightforward- \n1. movies_based_on_time - We will drop the genres here final schema will be (movie_id,name, Year)\n2. movies_based_on_genres - Final schema would look like (movie_id,name_with_year,one_genre)\n\nFrom the description at [kaggle](https://www.kaggle.com/grouplens/movielens-20m-dataset) we can see the schema of the files. for the sake of computation we would explicitly mention the schema(Spark can infer it itself but that involves an action which at most cases we want to minimize)"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import *\n#working only on movies.csv right now\nmovies_with_genres_df_schema = StructType(\n  [StructField('ID', IntegerType()),\n   StructField('title', StringType()),\n   StructField('genres',StringType())]\n  )\n\nmovies_df_schema = StructType(\n  [StructField('ID', IntegerType()),\n   StructField('title', StringType())]\n  ) #dropping the genres.Also, we will tranform the df to include the Year later"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#Creating the dataframes \nmovies_df = sqlContext.read.format('com.databricks.spark.csv').options(header=True, inferSchema=False).schema(movies_df_schema).load(movies_filename)\nmovies_with_genres_df = sqlContext.read.format('com.databricks.spark.csv').options(header=True, inferSchema=False).schema(movies_with_genres_df_schema).load(movies_filename)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["### Inspecting the DataFrames before the transformations"],"metadata":{}},{"cell_type":"code","source":["movies_df.show(4,truncate = False) #we will also use this for Collabrative filtering\nmovies_with_genres_df.show(4,truncate = False)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#transforming the Dataframes\nfrom pyspark.sql.functions import split, regexp_extract\n\n# Side note a very nice quote -- Some people, when confronted with a problem, think \"I know, I'll use regular expressions.\" Now they have two problems.(attributed to Jamie #Zawinski)\nmovies_with_year_df = movies_df.select('ID','title',regexp_extract('title',r'\\((\\d+)\\)',1).alias('year'))\n\n#one genre per row\nmovies_with_one_genre_df = sqlContext.createDataFrame(movies_with_genres_df.rdd.map(lambda (a,b,c): [(a,b,i) for i in c.split('|')])\\\n                                                      .flatMap(lambda x:x)).toDF('Id','title','one_genre') "],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["### DataFrames after Transformation"],"metadata":{}},{"cell_type":"code","source":["movies_with_one_genre_df.show(10,truncate = False)\nmovies_with_year_df.show(4,truncate = False)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["### Now we will use the inbuilt functionality of Databricks for some insights"],"metadata":{}},{"cell_type":"code","source":["display(movies_with_one_genre_df.groupBy('one_genre').count()) #people love drama\n\n#Below we have a bar chart here we can choose from a lot of other options"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["#from here we can look at the count and find that the maximum number of movies are produced in 2009\ndisplay(movies_with_year_df.groupBy('year').count().orderBy('count',ascending = False))"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["2 Observations from movies.csv\n1. People love Drama.\n2. And there are lot of movies each year."],"metadata":{}},{"cell_type":"markdown","source":["### Now let's move to Ratings\n\nWe already have the movie_df now we will require ratings Lets create the Dataframe"],"metadata":{}},{"cell_type":"code","source":["#again for avoiding the action we are explicitly defining the schema\nratings_df_schema = StructType(\n  [StructField('userId', IntegerType()),\n   StructField('movieId', IntegerType()),\n   StructField('rating', DoubleType())]\n)              #we are dropping the Time Stamp column"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#creating the df\nratings_df = sqlContext.read.format('com.databricks.spark.csv').options(header=True, inferSchema=False).schema(ratings_df_schema).load(ratings_filename)\nratings_df.show(4)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["#We will cache both the dataframes\nratings_df.cache()\nmovies_df.cache()\nprint \"both dataframes are in cache now for easy accessibility\""],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["### Global Popularity \nIt is good to know the most popular movies,and at times it is very hard to just beat popularity [Xavier Amatriain Lecture](https://www.youtube.com/watch?v=bLhq63ygoU8)\n Movies with highest average ratings here we will put a constraint on the no. of reviews given we will discard the movies where the count of ratings is less than 500."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import functions as F\n\n# From ratingsDF, create a movie_ids_with_avg_ratings_df that combines the two DataFrames\nmovie_ids_with_avg_ratings_df = ratings_df.groupBy('movieId').agg(F.count(ratings_df.rating).alias(\"count\"), F.avg(ratings_df.rating).alias(\"average\"))\nprint 'movie_ids_with_avg_ratings_df:'\nmovie_ids_with_avg_ratings_df.show(4, truncate=False)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["#this df will have names with movie_id- Make it more understandable\nmovie_names_with_avg_ratings_df = movie_ids_with_avg_ratings_df.join(movies_df,F.col('movieID') == F.col('ID')).drop('ID')\nmovie_names_with_avg_ratings_df.show(4,truncate = False)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["#so let us see the global popularity\nmovies_with_500_ratings_or_more = movie_names_with_avg_ratings_df.filter(movie_names_with_avg_ratings_df['count'] >= 500).orderBy('average',ascending = False)\nmovies_with_500_ratings_or_more.show(truncate = False)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["A good thing to notice above is it has a lot of similarity with the [IMDB top 250](http://www.imdb.com/chart/top)\n\nIf there is a cold start problem (New user) we can just recommend the global populars"],"metadata":{}},{"cell_type":"markdown","source":["## Collaborative filtering now\n[wikipedia article here](https://en.wikipedia.org/wiki/Collaborative_filtering). We will use the Matrix Factorization algoithm present in spark MLlib called [ALS quora explaination](https://www.quora.com/What-is-the-Alternating-Least-Squares-method-in-recommendation-systems)\n\n<img alt=\"factorization\" src=\"http://spark-mooc.github.io/web-assets/images/matrix_factorization.png\" style=\"width: 885px\"/>"],"metadata":{}},{"cell_type":"markdown","source":["### Splitting in Train, Test and Validation dataset\n\nAs with all the Machine Learning Algorithms in practice we have to tune parameters and then test accuracy.For this we will split the data into 3 parts Train, Test(Checking the final accuracy) and Validation(optimizing hyperparameters) data. For more information about this [brilliant lecture by Nando](https://www.youtube.com/watch?v=PvuN23m7hhY)"],"metadata":{}},{"cell_type":"code","source":["# We'll hold out 60% for training, 20% of our data for validation, and leave 20% for testing\nseed = 4\n(split_60_df, split_a_20_df, split_b_20_df) = ratings_df.randomSplit([0.6,0.2,0.2],seed)\n\n# Let's cache these datasets for performance\ntraining_df = split_60_df.cache()\nvalidation_df = split_a_20_df.cache()\ntest_df = split_b_20_df.cache()\n\nprint('Training: {0}, validation: {1}, test: {2}\\n'.format(\n  training_df.count(), validation_df.count(), test_df.count())\n)\ntraining_df.show(4,truncate = False)\nvalidation_df.show(4,truncate = False)\ntest_df.show(4,truncate = False)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["From above we can see approximately 10 million training samples, 4 million validation and 4 million test samples"],"metadata":{}},{"cell_type":"markdown","source":["### Alternating Least Square (ALS)\nthe documentation can be found [here](http://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS)\n\nNeed of Cross validation, some problems and solutions here I am copying it directly from the Assignment notebook\n\nA challenge for collaborative filtering is how to provide ratings to a new user (a user who has not provided *any* ratings at all). Some recommendation systems choose to provide new users with a set of default ratings (e.g., an average value across all ratings), while others choose to provide no ratings for new users. Spark's ALS algorithm yields a NaN (`Not a Number`) value when asked to provide a rating for a new user.\n\nUsing the ML Pipeline's [CrossValidator](http://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator) with ALS is thus problematic, because cross validation involves dividing the training data into a set of folds (e.g., three sets) and then using those folds for testing and evaluating the parameters during the parameter grid search process. It is likely that some of the folds will contain users that are not in the other folds, and, as a result, ALS produces NaN values for those new users. When the CrossValidator uses the Evaluator (RMSE) to compute an error metric, the RMSE algorithm will return NaN. This will make *all* of the parameters in the parameter grid appear to be equally good (or bad).\n\nYou can read the discussion on [Spark JIRA 14489](https://issues.apache.org/jira/browse/SPARK-14489) about this issue. There are proposed workarounds of having ALS provide default values or having RMSE drop NaN values. Both introduce potential issues. We have chosen to have RMSE drop NaN values. While this does not solve the underlying issue of ALS not predicting a value for a new user, it does provide some evaluation value. We manually implement the parameter grid search process using a for loop (below) and remove the NaN values before using RMSE.\n\nFor a production application, you would want to consider the tradeoffs in how to handle new users.\n\nI will try to write comments as explicit as possible in the next cell."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.recommendation import ALS\n\n# our ALS learner\nals = ALS()\n\n# Now we set the parameters for the method\nals.setMaxIter(5)\\\n   .setSeed(seed)\\\n   .setRegParam(0.1)\\\n   .setUserCol('userId')\\\n   .setItemCol('movieId')\\\n   .setRatingCol('rating')\n\n# Now let's compute an evaluation metric for our test and validation dataset\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n# Create an RMSE evaluator using the label and predicted columns\n#it will essentially calculate the rmse score based on these columns\nreg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\", metricName=\"rmse\")\n\ntolerance = 0.03\n\n#Now to understand rank let us initially assume that my recommendation matrix is 1000 * 1000 (1000 users and 1000 products this is a very sparse matrix)\n#Now what we do is we get 2 matrices P (shape 1000 * rank) and Q (shape rank * 1000) so essentially now if we multiply them I get the same but now the storage has decreased from storing 1000 * 1000 numbers to 2 * 1000 * rank (for rank = 4 we only need 8000 numbers compared to 1000000)  \nranks = [4, 8, 12] \nerrors = [0, 0, 0]\nmodels = [0, 0, 0]\nerr = 0\nmin_error = float('inf')\nbest_rank = -1\nfor rank in ranks:\n  # Set the rank here:\n  als.setRank(rank)\n  # Create the model with these parameters.\n  model = als.fit(training_df)\n  # Run the model to create a prediction. Predict against the validation_df.\n  predict_df = model.transform(validation_df)\n\n  # Remove NaN values from prediction (due to SPARK-14489)\n  predicted_ratings_df = predict_df.filter(predict_df.prediction != float('nan'))\n\n  # Run the previously created RMSE evaluator, reg_eval, on the predicted_ratings_df DataFrame\n  error = reg_eval.evaluate(predicted_ratings_df)\n  errors[err] = error\n  models[err] = model\n  print 'For rank %s the RMSE is %s' % (rank, error)\n  if error < min_error:\n    min_error = error\n    best_rank = err\n  err += 1\n\nals.setRank(ranks[best_rank])\nprint 'The best model was trained with rank %s' % ranks[best_rank]\nmy_model = models[best_rank]"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":["### Testing our Model\n\nAgain we will filter out where the prediction is NaN"],"metadata":{}},{"cell_type":"code","source":["# TODO: Replace <FILL_IN> with the appropriate code\n# In ML Pipelines, this next step has a bug that produces unwanted NaN values. We\n# have to filter them out. See https://issues.apache.org/jira/browse/SPARK-14489\npredict_df = my_model.transform(test_df)\n\n# Remove NaN values from prediction (due to SPARK-14489)\npredicted_test_df = predict_df.filter(predict_df.prediction != float('nan'))\n\n# Run the previously created RMSE evaluator, reg_eval, on the predicted_test_df DataFrame\ntest_RMSE = reg_eval.evaluate(predicted_test_df)\n\nprint('The model had a RMSE on the test set of {0}'.format(test_RMSE))"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":["### It is always good to just compare with the by Default model\nWhere we will just get the global average rating for our training dataset and get the RMSE based on it"],"metadata":{}},{"cell_type":"code","source":["default_value = training_df.agg(F.avg('rating')).collect()[0][0]\nprint default_value "],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["# Add a column with the average rating -- getting the RMSE based on a default value (which is same throughout)\ntest_for_avg_df = test_df.withColumn('prediction', F.lit(default_value))\n\n# Run the previously created RMSE evaluator, reg_eval, on the test_for_avg_df DataFrame\ntest_avg_RMSE = reg_eval.evaluate(test_for_avg_df)\n\nprint(\"The RMSE on the average set is {0}\".format(test_avg_RMSE)) "],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["Looking at the value we can say we have definitely improved on the RMSE"],"metadata":{}},{"cell_type":"markdown","source":["### Prediction based on our watched Movies"],"metadata":{}},{"cell_type":"code","source":["#lets look at the top movies because there would be high chance if I have seen them\ndisplay(movies_with_500_ratings_or_more)"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":["Let me pick 4 movies and put the ratings in:\n<pre>\nMy pick                     - my movie_id - my stars\nShawshank Redemption          318           3\n12 angry men                  1203          5\nForrest Gump                  356           5\nGodFather                     858           2 (Sorry in advance If the reader like it and I don't)\n</pre>"],"metadata":{}},{"cell_type":"markdown","source":["### Putting the values into Training dataset and training it again\nAs the User id 0 is not used so will use that for the user rating"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import Row\nmy_user_id = 0\n\n# Note that the movie IDs are the *last* number on each line. A common error was to use the number of ratings as the movie ID.\nmy_rated_movies = [\n     (0,318,3),(0,1203,5),(0,356,5),(0,858,2)\n     # The format of each line is (my_user_id, movie ID, your rating)\n     ]\n\nmy_ratings_df = sqlContext.createDataFrame(my_rated_movies, ['userId','movieId','rating'])\nprint 'My movie ratings:'\nmy_ratings_df.show()"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["#Now adding my_ratings to the training_df\ntraining_with_my_ratings_df = training_df.unionAll(my_ratings_df)\nprint \"the train data has %s more entries now\"%(training_with_my_ratings_df.count() - training_df.count())"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\n# Reset the parameters for the ALS object.\nals.setPredictionCol(\"prediction\")\\\n   .setMaxIter(5)\\\n   .setSeed(seed)\\\n   .setRegParam(0.1)\\\n   .setUserCol('userId')\\\n   .setItemCol('movieId')\\\n   .setRatingCol('rating')\\\n   .setRank(8)   #we got rank 8 as optimal\n\n\n# Create the model with these parameters.\nmy_ratings_model = als.fit(training_with_my_ratings_df)"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":["Looking for RMSE again"],"metadata":{}},{"cell_type":"code","source":["my_predict_df = my_ratings_model.transform(test_df)\n\n# Remove NaN values from prediction\npredicted_test_my_ratings_df = my_predict_df.filter(my_predict_df.prediction != float('nan'))\n\n# Run the previously created RMSE evaluator, reg_eval, on the predicted_test_my_ratings_df DataFrame\ntest_RMSE_my_ratings = reg_eval.evaluate(predicted_test_my_ratings_df)\nprint('The model had a RMSE on the test set of {0}'.format(test_RMSE_my_ratings))"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":["### Now finding the Movies which best suites me :)\n\nSome steps how we would achieve this:\n1. Here I have to first create a DF which has all the movies except what I already rated user id should be 0.\n2. Then predict the rating for them. \n3. And then finally choose the best 50 movies"],"metadata":{}},{"cell_type":"code","source":["my_rated_movies"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["# Create a list of my rated movie IDs\nmy_rated_movie_ids = [x[1] for x in my_rated_movies]\n\n# Filter out the movies I already rated.'~' sign will make sure not to include them.\nnot_rated_df = movies_df.filter(~ movies_df['ID'].isin(my_rated_movie_ids))\n\n# Rename the \"ID\" column to be \"movieId\", and add a column with my_user_id as \"userId\".\nmy_unrated_movies_df = not_rated_df.withColumnRenamed('ID','movieId').withColumn('userId',F.lit(0))\n\n# Use my_rating_model to predict ratings for the movies that I did not manually rate.\nraw_predicted_ratings_df = my_ratings_model.transform(my_unrated_movies_df)\n\npredicted_ratings_df = raw_predicted_ratings_df.filter(raw_predicted_ratings_df['prediction'] != float('nan'))"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["#some sample ratings\npredicted_ratings_df.show(4,truncate = False)"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"markdown","source":["One Last trick I don't want to see a movie which is very new I mean it should atleast have some reviews say 400 here"],"metadata":{}},{"cell_type":"code","source":["predicted_with_counts_df = predicted_ratings_df.join(movie_names_with_avg_ratings_df,predicted_ratings_df.movieId== movie_names_with_avg_ratings_df.movieId)\npredicted_highest_rated_movies_df = predicted_with_counts_df.filter(predicted_with_counts_df['count'] > 400).sort('prediction',ascending = False)\n\nprint ('My 50 highest rated movies as predicted (for movies with more than 400 reviews):')\npredicted_highest_rated_movies_df.show(50,truncate = False)"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":["Cool Sleepless in Seattle - Tom Hanks Movie will watch it"],"metadata":{}},{"cell_type":"markdown","source":["Next steps:\n1. Use another dataset (to get some content) so that it will be hybrid\n2. Probably use Deep Learning in a way"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":58}],"metadata":{"name":"Movie_Lens_20M","notebookId":3123150065672593},"nbformat":4,"nbformat_minor":0}
